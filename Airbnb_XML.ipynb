{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries we'll use\n",
    "import spacy # fast NLP\n",
    "import pandas as pd # dataframes\n",
    "import langid # language identification (i.e. what language is this?)\n",
    "from nltk.classify.textcat import TextCat # language identification from NLTK\n",
    "from matplotlib.pyplot import plot # not as good as ggplot in R :p\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirData=pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirData[\"comments\"]=AirData[\"comments\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tagged languages (estimated):\n",
      "49\n",
      "Percent of data in English (estimated):\n",
      "95.1476374041251\n"
     ]
    }
   ],
   "source": [
    "ids_langid = AirData[\"comments\"].apply(langid.classify)\n",
    "\n",
    "# get just the language label\n",
    "langs = ids_langid.apply(lambda tuple: tuple[0])\n",
    "\n",
    "# how many unique language labels were applied?\n",
    "print(\"Number of tagged languages (estimated):\")\n",
    "print(len(langs.unique()))\n",
    "\n",
    "# percent of the total dataset in English\n",
    "print(\"Percent of data in English (estimated):\")\n",
    "print((sum(langs==\"en\")/len(langs))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "English_comment=AirData[\"comments\"][langs=='en'].str.replace('[^\\w\\s]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def clean_html(raw_html): #Cleaning the reviews are required else Carrot2 fails\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    res = re.sub('[^\\w\\s]', '', raw_html) \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "description=English_comment\n",
    "description.str.encode('utf-8')#Your reviews might be here as a Series\n",
    "reviews_descriptions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our stay with Marcus in Bristol was fantastic in every way He was a great host  picking us up at the bus stop recommending places to try leaving plenty of pastries and other breakfast items to enjoy in the morning The flat itself was modern bright clean and spacious  and best of all right on Bristols lovely harbourside We will definitely stay again next time were in Bristol  thanks again Marcus\n"
     ]
    }
   ],
   "source": [
    "temp_list=description.tolist() #Convert your reviews in a list\n",
    "for item in temp_list:\n",
    "    if item in punc:\n",
    "        temp_list.remove(item)\n",
    "for item in temp_list: #Walk through each review\n",
    "    clean_string=clean_html(item) #Clean it\n",
    "    clean_string=clean_string.replace('\\n','').replace('/','')\n",
    "    reviews_descriptions.append(clean_string) #Append cleaned review to a list and then use this list to generate xml for Carrot2\n",
    "print(reviews_descriptions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(xml):\n",
    "    with io.open('airbnb_reviews_1000.xml', \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code for generating XML, instead of printing, you can output contents to a file, i.e. some_file.xml\n",
    "def generate_xml_file(reviews_description):\n",
    "    xml = ['<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n']\n",
    "    xml.append('<searchresult>\\n')\n",
    "    i=0\n",
    "    for item in reviews_description[1000:2000]: #this is the same list we created above\n",
    "        xml.append('<document id=\"{0}\">\\n'.format(i)) #we can create a document id auto generate that\n",
    "        xml.append('<title>\\n')\n",
    "        xml.append('{0}\\n'.format(item))\n",
    "        xml.append('</title>\\n')\n",
    "        xml.append('</document>\\n')\n",
    "        i+=1\n",
    "    xml.append('</searchresult>')\n",
    "    write_to_file(xml)\n",
    "    \n",
    "generate_xml_file(reviews_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
